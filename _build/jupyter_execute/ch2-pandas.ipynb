{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471dbd86",
   "metadata": {},
   "source": [
    "# Pandas ile Veri Analizi ve İşleme\n",
    "\n",
    "Bu bölümde, temel pandas veri yapılarını oluşturmadan verileri pandas ile analiz etmeye kadar, pandas'ın veri işleme ve analizi alanındaki yeteneklerini uygulama örnekleri ve pratik egzersizlerle göstererek size yardımcı olacak bir kısa bir kurs olarak verilmiştir. Bu bölümün sonunda, veri okuma ve yazma, veri çerçeveleri birleştirme, veri ön işleme, veri görselleştirme vb. temel deneyimleri kazanmış olacaksınız. Daha sonraki bölümlerinde daha ayrıntılı bir şekilde ele alacağımız kütüphanenin çoğu temel özelliklerini bu bölümde belirteceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93fa10",
   "metadata": {},
   "source": [
    "Python Pandas kütüphanesi, veri analizi ve işleme için kullanılan açık kaynaklı bir kütüphanedir. Bu kütüphane, veri manipülasyonu, filtreleme, görselleştirme ve veri analizi gibi birçok işlemi kolaylaştırır. Python programlama dilinde Pandas kütüphanesi kullanarak veri analizi yapmak oldukça kolaydır.\n",
    "\n",
    "Bu yazıda, Python Pandas kütüphanesi hakkında genel bir bilgi edineceğiz ve kütüphane ile nasıl veri analizi yapabileceğimizi öğreneceğiz. \n",
    "\n",
    "## pandas Kütüphanesi\n",
    "\n",
    "Pandas, Python programlama dilinde veri analizi için kullanılan bir kütüphanedir. Veri manipülasyonu, veri filtreleme, veri birleştirme, veri işleme, veri analizi ve veri görselleştirme gibi birçok işlemi yapmamıza yardımcı olur. Pandas, verileri düzenlemek, analiz etmek ve modellemek için yaygın olarak kullanılan bir araçtır.\n",
    "\n",
    "Pandas kütüphanesi, iki temel veri yapıları olan DataFrame ve Series sınıflarına dayanmaktadır. DataFrame, iki boyutlu bir veri yapısıdır ve sütunlar ve satırlar şeklinde organize edilir. Series, bir boyutlu bir veri yapısıdır ve sadece bir sütun içerir.\n",
    "\n",
    "### Nasıl yüklenir?\n",
    "\n",
    "Pandas kütüphanesi, Python programlama dilinin bir varsayılan kütüphanesi değildir ve sonradan yüklenmesi gerekmektedir. Pandas kütüphanesini yüklemek için aşağıdaki komutu kullanabilirsiniz:\n",
    "\n",
    "`pip install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "theoretical-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-scene",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__  # pandas versiyonu: '1.3.4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19770ab",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### pandas kullanım alanları\n",
    "\n",
    "Pandas, Python programlama dilinde yüksek performanslı ve kullanımı kolay veri analizi ve manipülasyonu kütüphanesidir. Pandas, özellikle tablo benzeri yapıdaki veriler üzerinde çalışmak için tasarlanmıştır ve sütun ve satırların adlandırılmasına ve indekslenmesine izin verir. Pandas ayrıca, veri okuma ve yazma işlemleri için de birçok araç sağlar.\n",
    "\n",
    "Pandas kütüphanesi ile yapılabilecek işlemler şu şekilde özetlenebilir:\n",
    "- Veri Okuma ve Yazma\n",
    "- Veri Seçme ve Sıralama\n",
    "- Veri Dönüştürme ve Temizleme\n",
    "- Veri Gruplama ve Birleştirm\n",
    "- Zaman Serisi Analizi\n",
    "- Veri Görselleştirme\n",
    "- Veri Modelleme ve Karşılaştırma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-python",
   "metadata": {},
   "source": [
    "## Veri Yapıları\n",
    "\n",
    "Pandas kütüphanesi, üç temel veri yapısı olan DataFrame, İndeks ve Series sınıflarına dayanmaktadır: Seriler (Series), Indeksler (Indexes) ve Veri Çerçeveleri (DataFrames)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866fb73",
   "metadata": {},
   "source": [
    "\n",
    "### Seriler (Series)\n",
    "\n",
    "Seriler, tek boyutlu bir veri yapısıdır ve birbirinden farklı veri tiplerini içerebilirler. Seriler, indeks ve değerlerden oluşur. Indeksler varsayılan olarak 0'dan başlayan tam sayılar olarak atanabilir veya belirtilen etiketleri kullanarak özelleştirilebilirler.\n",
    "\n",
    "Seriler, bir boyutlu bir veri yapısıdır ve sadece bir sütun içerir. Seriler, bir liste, dizi veya sözlük gibi bir veri yapısından oluşturulabilir. Seriler aslında veri çerçevesinin sütununu temsil eder.\n",
    "\n",
    "Aşağıdaki örnekte, bir Seriler nesnesi oluşturulup nesne üzerinde işlemler gösterilmiştir. Örnekler Jupyter Notebook üzerinde gerçekleştirilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa67892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    5\n",
      "3    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "veriler = [1, 2, 5, 8]\n",
    "seri_ornegi = pd.Series(veriler)\n",
    "\n",
    "print(seri_ornegi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20ccef",
   "metadata": {},
   "source": [
    "Aşağıdaki kod parçacıklarında Seriler hakkında çeşitli metotlara örnekler verilmiştir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2810ca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "[1 2 5 8]\n",
      "None\n",
      "(4,)\n",
      "Index(['a', 'b', 'c'], dtype='object')\n",
      "2    5\n",
      "3    8\n",
      "dtype: int64\n",
      "[ 0.   2.5  5.   7.5 10. ]\n",
      "0     NaN\n",
      "1     2.5\n",
      "2     7.5\n",
      "3    12.5\n",
      "4    17.5\n",
      "5     NaN\n",
      "dtype: float64\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(seri_ornegi.dtype)  # int64\n",
    "print(seri_ornegi.values)  # [1 2 5 8]\n",
    "print(seri_ornegi.name)  # seri_ornegi\n",
    "print(seri_ornegi.shape)  # (4,)\n",
    "\n",
    "seri_ornegi2 = pd.Series(\n",
    "    [2, 3, 4], index=['a', 'b', 'c'],\n",
    "    name='seri_ornegi')  # indeks değerlerinin değiştirilmesi\n",
    "print(seri_ornegi2.index)  # Index(['a', 'b', 'c'], dtype='object')\n",
    "\n",
    "print(seri_ornegi[seri_ornegi > 2])  # 2den büyük veriler\n",
    "\n",
    "sayilar = np.linspace(0, 10, num=5)\n",
    "print(sayilar)  # [ 0.   2.5  5.   7.5 10. ]\n",
    "\n",
    "x = pd.Series(sayilar)  # indeksler [0, 1, 2, 3, 4]\n",
    "y = pd.Series(sayilar, index=pd.Index([1, 2, 3, 4, 5]))\n",
    "\n",
    "print(x + y)  # indekslere göre toplama yapılır.\n",
    "\n",
    "# numpy da iki diziyi toplayınca\n",
    "print(np.array([1, 1, 1]) + np.array([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a82be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(2 in seri_ornegi)  # seri örneğinde 2 değeri var mı?\n",
    "print(10 in seri_ornegi)  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1d26f",
   "metadata": {},
   "source": [
    "Görüldüğü gibi Seriler tek boyutlu veri yapılarını temsil etmektedir. İki veya daha fazla boyuttaki veri tipleri ile ilgili ise Veri Çerçeveleri kullanılmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0228a226",
   "metadata": {},
   "source": [
    "### Veri Çerçeveleri (DataFrames)\n",
    "\n",
    "Veri Çerçeveleri, iki boyutlu bir veri yapısıdır ve birden çok Seriden oluşur. Veri Çerçeveleri, sütunlara ve satırlara göre indekslenir ve her sütun bir Seri nesnesi temsil eder. Her sütun farklı bir veri türüne sahip olabilir. Veri Çerçeveleri, birçok veri kaynağından okunabilir ve birçok farklı şekilde dönüştürülebilir.\n",
    "\n",
    "\n",
    "DataFrame, iki boyutlu bir veri yapısıdır ve sütunlar ve satırlar şeklinde organize edilir. DataFrame, tablo benzeri bir yapıya sahiptir ve her sütun bir Series nesnesidir. DataFrame'in her bir satırı, bir gözlem veya bir veri noktasını temsil eder. DataFrame, verileri işlemek ve manipüle etmek için birçok yöntem sağlar.\n",
    "\n",
    "Aşağıdaki örnekte, \"isim\", \"yas\" ve \"sehir\" sütunları olan bir DataFrame nesnesi oluşturur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94621268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri çerçevesi yardımı\n",
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03486150",
   "metadata": {},
   "source": [
    "<img src=\"https://i.vgy.me/x59RBD.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147beb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isim</th>\n",
       "      <th>yas</th>\n",
       "      <th>sehir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmet</td>\n",
       "      <td>28</td>\n",
       "      <td>İstanbul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehmet</td>\n",
       "      <td>22</td>\n",
       "      <td>Ankara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ali</td>\n",
       "      <td>30</td>\n",
       "      <td>İzmir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ayşe</td>\n",
       "      <td>25</td>\n",
       "      <td>Bursa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     isim  yas     sehir\n",
       "0   Ahmet   28  İstanbul\n",
       "1  Mehmet   22    Ankara\n",
       "2     Ali   30     İzmir\n",
       "3    Ayşe   25     Bursa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'isim': ['Ahmet', 'Mehmet', 'Ali', 'Ayşe'],\n",
    "        'yas': [28, 22, 30, 25],\n",
    "        'sehir': ['İstanbul', 'Ankara', 'İzmir', 'Bursa']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e38dd",
   "metadata": {},
   "source": [
    "### Veri çerçevesi oluşturma yöntemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a1548",
   "metadata": {},
   "source": [
    "Veri Çerçevelerini oluşturmak için yukarıdaki örnekte olduğu gibi tüm veriler listeler içerisine yazılabilir. Bununla birlikte birkaç yöntemden daha bahsetmemiz gerekirse aşağıdaki yöntemleri söyleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "occupied-lingerie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sütun 1</th>\n",
       "      <th>Sütun 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.470738</td>\n",
       "      <td>0.198176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.376816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.769168</td>\n",
       "      <td>0.094494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sütun 1   Sütun 2\n",
       "a  0.470738  0.198176\n",
       "b  0.372200  0.376816\n",
       "c  0.769168  0.094494"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri Çerçevesi oluşturma 1. yöntem\n",
    "veri_cercevesi = pd.DataFrame(np.random.rand(3, 2),\n",
    "                              columns=['Sütun 1', 'Sütun 2'],\n",
    "                              index=['a', 'b', 'c'])\n",
    "veri_cercevesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6fa46d",
   "metadata": {},
   "source": [
    "Veri çerçevesi oluşturmada 2. yöntem olarak Python veri tiplerinden `sözlükler (dictionary)` kullanılabilir. Sözlükler key:value tiplerinden oluşur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10286dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         plaka kodları  nufuslar\n",
      "istanbul            34  20000000\n",
      "sakarya             54   1000000\n",
      "kmaraş              46    900000\n"
     ]
    }
   ],
   "source": [
    "plakalar = {'istanbul':'34','sakarya':'54','kmaraş':'46'}\n",
    "nufus_sayilari = {'istanbul':20000000,'sakarya':1000000,'kmaraş':900000}\n",
    "sehirler = pd.DataFrame({'plaka kodları':plakalar,'nufuslar':nufus_sayilari})\n",
    "print(sehirler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bd79a",
   "metadata": {},
   "source": [
    "Eğer index ve sütun değerleri eşleşirse toplama gerçekleşir. Bu durumda `sehirler + sehirler` komutu aşağıdaki çıktıyı verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2201a159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plaka kodları</th>\n",
       "      <th>nufuslar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>istanbul</th>\n",
       "      <td>3434</td>\n",
       "      <td>40000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sakarya</th>\n",
       "      <td>5454</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kmaraş</th>\n",
       "      <td>4646</td>\n",
       "      <td>1800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         plaka kodları  nufuslar\n",
       "istanbul          3434  40000000\n",
       "sakarya           5454   2000000\n",
       "kmaraş            4646   1800000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sehirler + sehirler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620d89b0",
   "metadata": {},
   "source": [
    "sehirler iki boyutlu bir veri yapısına sahiptir. Bu veri yapısı Numpy nesnesine dönüştürülebilir. Bunun için kullanılması gereken komut `to_numpy` komutudur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b39237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['plaka kodları', 'nufuslar'], dtype='object')\n",
      "[['34' 20000000]\n",
      " ['54' 1000000]\n",
      " ['46' 900000]]\n",
      "[['34' 20000000]\n",
      " ['54' 1000000]\n",
      " ['46' 900000]]\n"
     ]
    }
   ],
   "source": [
    "print(sehirler.columns) # Index(['plaka kodları', 'nufuslar'], dtype='object')\n",
    "print(sehirler.values)\n",
    "print(sehirler.values)\n",
    "sehirler_numpy = sehirler.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3662ad",
   "metadata": {},
   "source": [
    "Veri Çerçevesi oluşturmanın üçüncü yöntemi de liste fonksiyonları kullanmaktır. Bu duruma örnek aşağıdaki kod parçacıklarında verilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "471e4246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>karesi</th>\n",
       "      <th>kubu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  karesi  kubu\n",
       "0  0       0     0\n",
       "1  1       1     1\n",
       "2  2       4     8\n",
       "3  3       9    27\n",
       "4  4      16    64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veri_listesi = [(n, n**2, n**3) for n in range(5)] # list comprehensions\n",
    "pd.DataFrame(veri_listesi, columns=['n', 'karesi', 'kubu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68483b",
   "metadata": {},
   "source": [
    "Son olarak Veri Çerçeveleri `random` modülü ile oluşturulabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf8d671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929616\n",
       "1    0.316376\n",
       "2    0.183919\n",
       "3    0.204560\n",
       "4    0.567725\n",
       "Name: rassal, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "pd.Series(np.random.rand(5), name='rassal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a177376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rassal</th>\n",
       "      <th>hava durumu</th>\n",
       "      <th>karar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tarih</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>0.929616</td>\n",
       "      <td>sicak</td>\n",
       "      <td>Dışarı Çıkma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>0.316376</td>\n",
       "      <td>ilik</td>\n",
       "      <td>Dışarı Çıkma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>0.183919</td>\n",
       "      <td>soguk</td>\n",
       "      <td>Dışarı Çık</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>0.204560</td>\n",
       "      <td>yagmurlu</td>\n",
       "      <td>Dışarı Çıkma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>0.567725</td>\n",
       "      <td>karli</td>\n",
       "      <td>Dışarı Çıkma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rassal hava durumu         karar\n",
       "tarih                                         \n",
       "2018-01-01  0.929616       sicak  Dışarı Çıkma\n",
       "2018-01-02  0.316376        ilik  Dışarı Çıkma\n",
       "2018-01-03  0.183919       soguk    Dışarı Çık\n",
       "2018-01-04  0.204560    yagmurlu  Dışarı Çıkma\n",
       "2018-01-05  0.567725       karli  Dışarı Çıkma"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "disari_cikma = pd.DataFrame(\n",
    "    {\n",
    "        'rassal': np.random.rand(5),\n",
    "        'hava durumu': ['sicak', 'ilik', 'soguk', 'yagmurlu', 'karli'],\n",
    "        'karar': [np.random.choice(['Dışarı Çık', 'Dışarı Çıkma']) for _ in range(5)]\n",
    "    },\n",
    "    index=pd.date_range(start='1/1/2018',\n",
    "                        freq='1D',\n",
    "                        periods=5,\n",
    "                        name='tarih'))\n",
    "\n",
    "disari_cikma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b59411",
   "metadata": {},
   "source": [
    "Veri Çerçevesindeki herhangi bir sütuna ulaşmak için iki yöntem kullanılabilir. Birincisinde köşeli parantez içerisinde sütun ismi verilir. Bu durumda sütun isminde boşluk gibi durumların olması çağırmayı etkilemez. İkinci yöntem olan nokta kullanımında ise boşluk gibi özel karakterlerin kullanılması mümkün değildir. Bu kullanımlara örnekler aşağıda verilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e37537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarih\n",
      "2018-01-01    Dışarı Çıkma\n",
      "2018-01-02    Dışarı Çıkma\n",
      "2018-01-03      Dışarı Çık\n",
      "2018-01-04    Dışarı Çıkma\n",
      "2018-01-05    Dışarı Çıkma\n",
      "Freq: D, Name: karar, dtype: object\n",
      "tarih\n",
      "2018-01-01    Dışarı Çıkma\n",
      "2018-01-02    Dışarı Çıkma\n",
      "2018-01-03      Dışarı Çık\n",
      "2018-01-04    Dışarı Çıkma\n",
      "2018-01-05    Dışarı Çıkma\n",
      "Freq: D, Name: karar, dtype: object"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(disari_cikma[\"karar\"]) # dışarı çıkma kararı series oldu\n",
    "print(disari_cikma.karar)# yukarıdaki ile aynı kullanıma sahiptir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75d250",
   "metadata": {},
   "source": [
    "### Indeksler (Index)\n",
    "\n",
    "Pandas Serilerini numpy tek boyutlu dizilerden ayıran nokta indeks değerleridir. Indeks veri tipi sayesinde satır kayıtlarına etiketler ile ulaşılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01790589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=4, step=1)\n",
      "<class 'pandas.core.indexes.range.RangeIndex'>\n",
      "True\n",
      "Int64Index([3, 4], dtype='int64')\n",
      "Int64Index([1, 2, 3, 4, 5], dtype='int64')\n",
      "Int64Index([5], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "indexler = seri_ornegi.index\n",
    "print(indexler) # Index(['a', 'b', 'c'], dtype='object')\n",
    "print(type(indexler)) # <class 'pandas.core.indexes.base.Index'>\n",
    "print(indexler.is_unique) # indeksler tekil verilerden mi oluşuyor mu? True\n",
    "\n",
    "# indeksler: Değiştirilemez listelerdir.\n",
    "\n",
    "indeks_1 = pd.Index([1,2,3,4])\n",
    "indeks_2 = pd.Index([3,4,5])\n",
    "\n",
    "print(indeks_1.intersection(indeks_2)) # Kesişim: Int64Index([3, 4], dtype='int64')\n",
    "print(indeks_1.union(indeks_2)) # Birleşim Int64Index([1, 2, 3, 4, 5], dtype='int64')\n",
    "print(indeks_2.difference(indeks_1)) # Fark Int64Index([5], dtype='int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5cae8",
   "metadata": {},
   "source": [
    "## Veri Giriş / Çıkış İşlemleri\n",
    "\n",
    "Pandas ile işlem yaparken çoğu kez farklı kaynak dosyalarından veri alma ve çıktıları farklı formatlarda yazmak gerekecektir. Bu işlemler, veri ile çalışırken vazgeçilmez işlemlerdir. Aşağıdaki komutlar ile, farklı dosya tipleri ile işlemler gerçekleştirilebilir.\n",
    "- text dosyası `genfromtxt`\n",
    "- csv dosyası `read_csv`\n",
    "- Excel dosyası `read_excel`\n",
    "- json dosyası `read_json()`\n",
    "- Veritabanından `read_sql()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0a1f0",
   "metadata": {},
   "source": [
    "### Verilerin Okunması\n",
    "\n",
    "Burada bir uygulama üzerinde veri giriş çıkış ve kayıt işlemleri gerçekleştirilecektir. Uygulama için [bu adreste](https://figshare.com/ndownloader/files/40286887) yer alan veri seti kullanılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "irish-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV dosyasının okunması\n",
    "calisan_verileri = pd.read_csv(\"https://figshare.com/ndownloader/files/40286887\",\n",
    "                               skiprows=0,\n",
    "                               sep=',',\n",
    "                               header=0,\n",
    "                               index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea9571b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Last Login Time</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "      <th>Senior Management</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>8/6/1993</td>\n",
       "      <td>12:42 PM</td>\n",
       "      <td>97308</td>\n",
       "      <td>6.945</td>\n",
       "      <td>True</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>3/31/1996</td>\n",
       "      <td>6:53 AM</td>\n",
       "      <td>61933</td>\n",
       "      <td>4.170</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>4/23/1993</td>\n",
       "      <td>11:17 AM</td>\n",
       "      <td>130590</td>\n",
       "      <td>11.858</td>\n",
       "      <td>False</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>3/4/2005</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>138705</td>\n",
       "      <td>9.340</td>\n",
       "      <td>True</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1/24/1998</td>\n",
       "      <td>4:47 PM</td>\n",
       "      <td>101004</td>\n",
       "      <td>1.389</td>\n",
       "      <td>True</td>\n",
       "      <td>Client Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>11/23/2014</td>\n",
       "      <td>6:09 AM</td>\n",
       "      <td>132483</td>\n",
       "      <td>16.655</td>\n",
       "      <td>False</td>\n",
       "      <td>Distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1/31/1984</td>\n",
       "      <td>6:30 AM</td>\n",
       "      <td>42392</td>\n",
       "      <td>19.675</td>\n",
       "      <td>False</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>5/20/2013</td>\n",
       "      <td>12:39 PM</td>\n",
       "      <td>96914</td>\n",
       "      <td>1.421</td>\n",
       "      <td>False</td>\n",
       "      <td>Product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>4/20/2013</td>\n",
       "      <td>4:45 PM</td>\n",
       "      <td>60500</td>\n",
       "      <td>11.985</td>\n",
       "      <td>False</td>\n",
       "      <td>Business Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>5/15/2012</td>\n",
       "      <td>6:24 PM</td>\n",
       "      <td>129949</td>\n",
       "      <td>10.169</td>\n",
       "      <td>True</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Start Date Last Login Time  Salary  Bonus % Senior Management  \\\n",
       "Gender                                                                  \n",
       "Male      8/6/1993        12:42 PM   97308    6.945              True   \n",
       "Male     3/31/1996         6:53 AM   61933    4.170              True   \n",
       "Female   4/23/1993        11:17 AM  130590   11.858             False   \n",
       "Male      3/4/2005         1:00 PM  138705    9.340              True   \n",
       "Male     1/24/1998         4:47 PM  101004    1.389              True   \n",
       "...            ...             ...     ...      ...               ...   \n",
       "NaN     11/23/2014         6:09 AM  132483   16.655             False   \n",
       "Male     1/31/1984         6:30 AM   42392   19.675             False   \n",
       "Male     5/20/2013        12:39 PM   96914    1.421             False   \n",
       "Male     4/20/2013         4:45 PM   60500   11.985             False   \n",
       "Male     5/15/2012         6:24 PM  129949   10.169              True   \n",
       "\n",
       "                        Team  \n",
       "Gender                        \n",
       "Male               Marketing  \n",
       "Male                     NaN  \n",
       "Female               Finance  \n",
       "Male                 Finance  \n",
       "Male         Client Services  \n",
       "...                      ...  \n",
       "NaN             Distribution  \n",
       "Male                 Finance  \n",
       "Male                 Product  \n",
       "Male    Business Development  \n",
       "Male                   Sales  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calisan_verileri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02c97e",
   "metadata": {},
   "source": [
    "Pandas içerisindeki önemli fonksiyonlardan birisi `read_csv`fonksiyonudur. Bu fonksiyon CSV dosyalarını pandas DataFrame veri yapısına dönüştürmek için kullanılır. Bu yöntem aşağıdaki parametrelerle çağrılabilir:\n",
    "\n",
    "- `filepath_or_buffer`: Okunacak CSV dosyasının yolu ya da URL'si.\n",
    "- `sep`: Dosya içerisindeki sütunları ayırmak için kullanılacak ayırıcı karakteri belirtir. Varsayılan ayırıcı virgüldür.\n",
    "- `delimiter`: Dosya içerisindeki sütunları ayırmak için kullanılacak ayırıcı karakteri belirtir. sep parametresiyle aynı işlevi görür.\n",
    "- `header`: Başlık satırının (sütun adları) var olup olmadığını belirtir. Varsayılan değer infer ile, ilk satırdaki değerlere göre otomatik olarak belirlenir.\n",
    "- `index_col`: Veri setinde hangi sütunun index olarak kullanılacağını belirtir.\n",
    "- `usecols`: Hangi sütunların alınacağını belirtir. Varsayılan olarak tüm sütunlar alınır.\n",
    "- `dtype`: Sütunların veri tiplerini belirtir.\n",
    "- `skiprows`: Dosyadaki belirtilen satır sayısı kadar okunmadan atlanır.\n",
    "- `skipfooter`: Dosyanın sonundan belirtilen satır sayısı kadar okunmadan atlanır.\n",
    "- `nrows`: Okunacak maksimum satır sayısını belirtir.\n",
    "- `na_values`: Boş veya eksik verilerin nasıl işleneceğini belirtir. Varsayılan olarak, herhangi bir boş veya eksik veri NAN olarak belirlenir.\n",
    "- `encoding`: Dosyanın karakter kodlamasını belirtir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46228712",
   "metadata": {},
   "source": [
    "### Online kaynaktan veri okunması\n",
    "\n",
    "Pandas, web sayfalarından veya online kaynaklardan veri okumak için birkaç farklı yöntem sunar. Bunlar arasında `read_html()`, `read_json()`, `read_csv()` ve `read_excel()` gibi popüler yöntemler yer alır. Bu yöntemler, farklı dosya türlerini veya veri kaynaklarını okumak için kullanılabilirler.\n",
    "\n",
    "Aşağıdaki örnekte, bir web sayfasından veri okunur ve DataFrame nesnesi olarak döndürülür:\n",
    "\n",
    "<img src=\"https://i.vgy.me/BvgiGg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37f03815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country / Area</th>\n",
       "      <th>UN continentalregion[4]</th>\n",
       "      <th>UN statisticalsubregion[4]</th>\n",
       "      <th>Population(1 July 2022)</th>\n",
       "      <th>Population(1 April 2023)</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>1428627663</td>\n",
       "      <td>+0.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China[a]</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Eastern Asia</td>\n",
       "      <td>1425887337</td>\n",
       "      <td>1425671352</td>\n",
       "      <td>−0.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Northern America</td>\n",
       "      <td>338289857</td>\n",
       "      <td>339996564</td>\n",
       "      <td>+0.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Asia</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>275501339</td>\n",
       "      <td>277534123</td>\n",
       "      <td>+0.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Southern Asia</td>\n",
       "      <td>235824863</td>\n",
       "      <td>240485658</td>\n",
       "      <td>+1.98%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country / Area UN continentalregion[4] UN statisticalsubregion[4]  \\\n",
       "0          India                    Asia              Southern Asia   \n",
       "1       China[a]                    Asia               Eastern Asia   \n",
       "2  United States                Americas           Northern America   \n",
       "3      Indonesia                    Asia         South-eastern Asia   \n",
       "4       Pakistan                    Asia              Southern Asia   \n",
       "\n",
       "   Population(1 July 2022)  Population(1 April 2023)  Change  \n",
       "0               1417173173                1428627663  +0.81%  \n",
       "1               1425887337                1425671352  −0.02%  \n",
       "2                338289857                 339996564  +0.50%  \n",
       "3                275501339                 277534123  +0.74%  \n",
       "4                235824863                 240485658  +1.98%  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web sayfasındaki tablo verisini okuma\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)'\n",
    "\n",
    "data = pd.read_html(url)\n",
    "\n",
    "# İlk tabloyu alalım\n",
    "df = data[0]\n",
    "\n",
    "# DataFrame'i göster\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc8ca6",
   "metadata": {},
   "source": [
    "Bu örnekte, `pd.read_html()` yöntemi, bir URL'yi parametre olarak alır ve bu URL'deki sayfada yer alan tüm tabloları içeren bir liste döndürür. Bizim örneğimizde, birinci tabloyu seçtik ve bir DataFrame nesnesi olarak döndürdük. Sonuç olarak, df değişkeni, web sayfasındaki ilk tabloyu içeren bir DataFrame nesnesi olarak oluşturuldu.\n",
    "\n",
    "Ayrıca, `pd.read_json()` gibi diğer yöntemler de benzer şekilde kullanılabilir. Bu yöntemler, farklı veri türleri için özelleştirilmiş seçenekler ve parametreler sunarlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b013331",
   "metadata": {},
   "source": [
    "### Verilerin Kaydedilmesi\n",
    "\n",
    "pandas kütüphanesi, farklı dosya biçimleri için çeşitli yazdırma metotları sunar. Bazı örnekler aşağıdaki gibidir:\n",
    "\n",
    "to_csv: Bu metot, verileri bir CSV dosyasına yazdırmak için kullanılır. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66fdae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame'i bir CSV dosyasına yazdır\n",
    "calisan_verileri.to_csv('calisan_verileri.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267ede0",
   "metadata": {},
   "source": [
    "Bu örnekte, `to_csv()` metodu kullanılarak bu veriler calisan_verileri.csv dosyasına yazdırılır. index=False parametresi, verilerin index sütununu dahil etmemeyi sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed0abc",
   "metadata": {},
   "source": [
    "to_csv() yöntemi, verileri CSV dosyasına yazarken belirli bir klasöre kaydetmek için `path_or_buf` parametresini kullanır. Bu parametreye tam bir dosya yolu veya dosya adı verilebilir. Ayrıca, alt dizinleri de dahil ederek farklı klasörlere kaydetmek için dosya yolu belirtirken dizin adı da kullanılabilir.\n",
    "\n",
    "- normal şekilde kayıt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dff2d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/calisan_verileri.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4196/25051184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalisan_verileri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/calisan_verileri.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/calisan_verileri.csv'"
     ]
    }
   ],
   "source": [
    "calisan_verileri.to_csv('./data/calisan_verileri.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c93ad",
   "metadata": {},
   "source": [
    "Bu örnekte, ./data yolunu kullanarak calisan_verileri.csv dosyasını data klasörü altında oluşturduk. Bu örneğin çalışabilmesi için çalışma klasörününün içerisine data adında bir klasör oluşturmak gerekmektedir. index=False parametresi, DataFrame'in satır dizinlerinin CSV dosyasına yazılmamasını sağlar. Eğer index=True olarak ayarlanırsa, satır dizinleri CSV dosyasına yazdırılacaktır.\n",
    "\n",
    "Klasörlerin konumları ile ilgili şunları bilmek gereklidir.\n",
    "\n",
    "'./' dizini, bulunduğumuz çalışma dizinini temsil eder. Bu nedenle, './data' ifadesi, bulunduğunuz dizin içindeki 'data' adlı bir alt dizine işaret eder. '.' karakteri, mevcut dizini ifade etmek için kullanılır.\n",
    "\n",
    "'..' ise bir üst dizini ifade eder. Örneğin, '../data' ifadesi, mevcut dizinin bir üstündeki dizindeki 'data' adlı bir alt dizine işaret eder.\n",
    "\n",
    "'\\' karakteri, Windows işletim sistemlerinde dosya yollarında kullanılan bir kaçış karakteridir. Bu karakter, dosya yolu bölümlerini ayırmak için kullanılır. Örneğin, \"C:\\Users\\kullanici_adi\\Desktop\" ifadesinde, '\\' karakterleri \"C:\", \"Users\", \"kullanici_adi\" ve \"Desktop\" gibi dosya yolu bölümlerini ayırmak için kullanılır. Unix tabanlı işletim sistemlerinde ise '/' karakteri kullanılır.\n",
    "\n",
    "Python'da da '\\' karakteri kaçış karakteri olarak kullanılır. Ancak, Windows işletim sistemlerinde olduğu gibi dosya yollarında kullanılan '\\' karakterleri yerine, Python'da Unix tabanlı işletim sistemlerinde olduğu gibi '/' karakterleri kullanılır. Bunun nedeni, Windows işletim sisteminde '\\' karakterinin kaçış karakteri olarak kullanılmasıdır ve dosya yollarında kullanılan '' karakteri tek başına bir kaçış karakteri olarak algılandığından, dosya yolu yazımında hatalara yol açabilmektedir.\n",
    "\n",
    "Bununla birlikte Python'da iki tane arka arkaya '\\' karakteri, bir tanesi normal bir karakter olarak kabul edilip diğerinin kaçış karakteri olarak kabul edilmesini sağlamak için kullanılır. Örneğin, \"\\\\server\\path\\filename\" ifadesinde, iki tane '\\' karakteri, dosya yolunda kullanılan normal '' karakterleri ve kaçış karakterleri arasında bir ayırıcı olarak işlev görür. Bu ifadede, ilk iki '\\' karakteri, '\\server' dizini için normal '' karakterleridir. Sonraki iki '\\' karakteri, '\\path' dizini için normal '' karakterleridir. Ve son olarak, son '\\' karakteri, dosya adı olan 'filename' için normal '' karakteridir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e8dcd",
   "metadata": {},
   "source": [
    "- `os` modülü kullanarak kayıt\n",
    "\n",
    "`os` modülü kullanarak da dosyaları farklı klasörlere kaydedebilirsiniz. Eğer data klasörü yoksa oluştur komutunu da burada verebilirsiniz. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = './data'\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "file_path = os.path.join(folder_path, 'calisan_verileri.csv')\n",
    "calisan_verileri.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231cd69",
   "metadata": {},
   "source": [
    "Bu örnekte, os modülü kullanılarak öncelikle ./data klasörü oluşturulur. Daha sonra, os.path.join() yöntemi kullanarak calisan_verileri.csv dosyasının tam yolu oluşturulur ve DataFrame to_csv() yöntemi kullanılarak bu dosyaya yazdırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361c1ad",
   "metadata": {},
   "source": [
    "`to_excel`: Bu metot, verileri bir Excel dosyasına yazdırmak için kullanılır. Örnek kullanımı:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame'i bir Excel dosyasına yazdır\n",
    "calisan_verileri.to_excel('calisan_verileri.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d47e57",
   "metadata": {},
   "source": [
    "Elde edilen Excel dosyası açıldığında aşağıdaki gibi düzgün bir çıktı alınacaktır.\n",
    "\n",
    "| ![](https://bit.ly/3GSSYbx) |\n",
    "|:--:|\n",
    "| Şekil 6 - Excel Ekran Görüntüsü|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3939157",
   "metadata": {},
   "source": [
    "`to_sql`: Bu metot, verileri bir SQL veritabanına yazdırmak için kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051372f",
   "metadata": {},
   "source": [
    "## pandas Veri Tipleri\n",
    "\n",
    "Pandas veri yapıları, aşağıdaki veri tiplerini içerebilir:\n",
    "\n",
    "- float: Ondalık sayıları temsil eder. Örneğin, 3.14 gibi.\n",
    "- int: Tam sayıları temsil eder. Örneğin, 42 gibi.\n",
    "- bool: True ve False mantıksal değerlerini temsil eder.\n",
    "- datetime: Tarih ve zaman değerlerini temsil eder. Örneğin, \"2022-01-01 12:00:00\" gibi.\n",
    "- timedelta: İki tarih veya zaman arasındaki farkı temsil eder.\n",
    "- object: Stringler, listeler, sözlükler, vb. nesneleri temsil eder.\n",
    "\n",
    "Pandas, bu temel veri yapılarına ek olarak, Categorical ve Sparse veri yapıları da sunar. Categorical veri yapısı, kategorik verileri temsil etmek için kullanılır ve Sparse veri yapısı, verilerin seyrek veya büyük olduğu durumlarda bellek kullanımını optimize etmek için kullanılır.\n",
    "\n",
    "`dtypes`, bir veri çerçevesinin tüm sütunlarının veri tiplerini gösteren bir özelliktir. Pandas DataFrame'i, farklı veri tiplerini (int, float, bool, string, datetime vb.) içeren sütunlardan oluşabilir. Her bir sütunun veri tipi, o sütundaki verilerin nasıl işleneceğini belirler.\n",
    "\n",
    "`dtypes`, DataFrame'deki sütunların veri tiplerini gösteren bir Seri nesnesi döndürür. Bu özellik, DataFrame'deki her sütunun veri tipini belirlemek ve herhangi bir sütunun veri tipini değiştirmek gibi işlemler yapmak için kullanılabilir. Ayrıca, farklı veri tiplerine sahip sütunların DataFrame'deki verileri nasıl işlediğini anlamak için de kullanılabilir. Örneğin, bir sütunun tamsayı değerleri taşıması ve daha sonra ondalık sayılara dönüştürülmesi isteniyorsa, bu özellik, ilgili sütunun veri tipini değiştirmek için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f327ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a978e51",
   "metadata": {},
   "source": [
    "`info()` metodu ise, DataFrame'in bellekteki boyutunu, sütunların isimlerini, dolu hücrelerin sayısını ve her sütundaki veri tiplerinin sayısını görüntüler. Bu metot ayrıca bellekteki DataFrame'in bellek kullanımı ve veri tipleri hakkında da bilgi sağlar.\n",
    "\n",
    "Ayrıca, her bir sütundaki eksik değerlerin sayısını ve veri tiplerinin bellek boyutunu da verir. Bu bilgi, veri seti üzerinde eksik değerlerin olduğu veya yanlış veri tipleri kullanıldığı durumlarda hataların nedenini anlamak için kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ac492",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.info()  # non-null sayılarını görmek için"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270e700",
   "metadata": {},
   "source": [
    "Bununla birlikte bazı durumlarda veri tipleri arasında değişiklik yapılmak istenebilir. Bunun için `astype()` metodu kullanılabilir. Bu metot, Pandas DataFrame sütunlarının veri tiplerini değiştirmek için kullanılır. Bu yöntem, mevcut bir DataFrame'deki bir veya daha fazla sütunun veri tipini değiştirerek, veri analizi veya veri manipülasyonu için daha uygun bir formata dönüştürmeye olanak tanır.\n",
    "\n",
    "Örneğin, bir sütunun veri tipini sayısal bir formattan tarih veya saat formatına dönüştürmek isteyebilirsiniz. Bu durumda, `astype()` yöntemini kullanarak sütunun veri tipini değiştirebilirsiniz.\n",
    "\n",
    "Ayrıca, `astype()`, sayısal sütunları float veya integer veri tiplerine dönüştürerek hesaplama işlemlerinin hızını arttırmaya da yardımcı olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d493be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri['Salary'] = calisan_verileri['Salary'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6256e",
   "metadata": {},
   "source": [
    "Yukarıdaki örnekte, `astype()` yöntemi kullanılarak 'Salary' sütununun veri tipi integer'dan float'a değiştirildi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a189236",
   "metadata": {},
   "source": [
    "### Veriler arasındaki dönüşümler\n",
    "\n",
    "Pandas, bir veri tipinden diğerine dönüştürmek için birkaç farklı seçenek sunar. Bazı yaygın dönüşüm işlemleri şunları içerir:\n",
    "\n",
    "- `astype()`: Bu yöntem, bir DataFrame sütununu veya Serisi'ni başka bir veri tipine dönüştürmek için kullanılır. Örneğin, bir sayısal sütunu metinsel bir sütuna dönüştürebilirsiniz. Bu yöntem, belirli bir veri tipi için bir seçenek belirleyebilir veya geniş bir yelpaze sunan `category`, `datetime64`, `timedelta` vb. gibi özel veri tipleri için kullanılabilir.\n",
    "\n",
    "`to_numeric()`: Bu yöntem, bir seriyi sayısal veri tipine dönüştürmek için kullanılır. Örneğin, bir serinin `object` veri tipinden `float` veya `int` veri tipine dönüştürebilirsiniz.\n",
    "\n",
    "`to_datetime()`: Bu yöntem, bir Serisi'ni tarih / saat veri tipine dönüştürmek için kullanılır. Örneğin, bir seriyi `object` veya `string` veri tipinden `datetime64` veri tipine dönüştürebilirsiniz.\n",
    "\n",
    "`to_timedelta()`: Bu yöntem, bir seriyi zaman aralığı (timedelta) veri tipine dönüştürmek için kullanılır. Örneğin, bir seriyi \"object\" veya \"string\" veri tipinden \"timedelta\" veri tipine dönüştürebilirsiniz.\n",
    "\n",
    "Aşağıdaki örnekler, bir veri tipinin diğerine nasıl dönüştürüleceğini gösterir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype() yöntemi\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': ['x', 'y', 'z']})\n",
    "df['A'] = df['A'].astype(str)   # 'A' sütununu str veri tipine dönüştürür\n",
    "df['B'] = df['B'].astype('category')  # 'B' sütununu category veri tipine dönüştürür\n",
    "\n",
    "# to_numeric() yöntemi\n",
    "s = pd.Series(['1', '2', '3'])\n",
    "s = pd.to_numeric(s)   # Serisi'ni sayısal veri tipine dönüştürür\n",
    "\n",
    "# to_datetime() yöntemi\n",
    "s = pd.Series(['2021-01-01', '2021-02-01', '2021-03-01'])\n",
    "s = pd.to_datetime(s)  # Serisi'ni datetime64 veri tipine dönüştürür\n",
    "\n",
    "# to_timedelta() yöntemi\n",
    "s = pd.Series(['1 days', '2 days', '3 days'])\n",
    "s = pd.to_timedelta(s)   # Serisi'ni timedelta veri tipine dönüştürür\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b2a25",
   "metadata": {},
   "source": [
    "Bu örneklerde, `astype()`, `to_numeric()`, `to_datetime()` ve `to_timedelta()` yöntemleri kullanılarak farklı veri tiplerinin dönüşümü, verilerin analizi sırasında sık sık gereklidir. Pandas, çeşitli veri tipleri arasında dönüşüm yapabilen esnek bir kütüphanedir.\n",
    "\n",
    "Bununla birlikte, dönüştürme işlemlerinin her zaman otomatik olarak başarılı olması garanti edilemez. Verilerin doğru şekilde dönüştürülüp dönüştürülmediğini kontrol etmek için, dönüştürme işlemi sonrası verilerin tekrar kontrol edilmesi önemlidir. Ayrıca, verileri dönüştürmek, verilerin boyutlarını da değiştirebilir. Bu nedenle, dönüştürme işlemi sırasında oluşabilecek olası veri kaybı veya hataların farkında olmak da önemlidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f7fbc",
   "metadata": {},
   "source": [
    "## Veri Seti Üzerinde İşlemler\n",
    "Veri seti çok sayıda veriden oluşmaktadır. Bu nedenle veri setinin doğru şekilde alındığını göstermek açısından ilk satırlarının yazdırılması faydalı olacaktır. Bunun için `head()` metodu kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.head(2)  # ilk 2 veri\n",
    "print(calisan_verileri.empty)  # False\n",
    "print(calisan_verileri.shape)  # (1000, 7),\n",
    "print(type(calisan_verileri))  # <class 'pandas.core.frame.DataFrame'>\n",
    "print(calisan_verileri.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"bu veri setinde {} adet veri vardır. Ayrıca özellik sayısı {}'dir.\".\n",
    "    format(calisan_verileri.shape[0], calisan_verileri.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7696e1",
   "metadata": {},
   "source": [
    "Pandas kütüphanesi DataFrame ve Series veri tiplerinde kullanılan `describe()` fonksiyonu, temel istatistiksel bilgileri özetleyen bir tablo oluşturur. Bu istatistiksel bilgiler arasında ortalama, standart sapma, minimum değer, maksimum değer, medyan, çeyreklikler ve veri sayısı yer alır.\n",
    "\n",
    "`describe()` fonksiyonu, özellikle veri setinin özetini hızlı bir şekilde elde etmek istediğinizde kullanışlıdır. Fonksiyon, sayısal verilerin yanı sıra kategorik veriler hakkında da bazı temel istatistiksel bilgiler sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.describe() # veri özetleme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8171c9",
   "metadata": {},
   "source": [
    "Bu örnekte, `describe()` fonksiyonu calisan_verileri DataFrame'ine uygulanmış ve istatistiksel bilgileri özetleyen bir tablo oluşturulmuştur.\n",
    "\n",
    "Bu tablo, maaş ve Bonus sütunları için temel istatistiksel bilgileri özetlemektedir. Çıktı aşağıdaki gibi görünecektir:\n",
    "\n",
    "![](https://i.vgy.me/vjCarD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a20342",
   "metadata": {},
   "source": [
    "`describe()` fonksiyonu, varsayılan olarak sadece sayısal sütunlar için çalışır. Bununla birlikte, include parametresi kullanılarak belirli sütun türleri de tanımlanabilir. Örneğin, tüm sütunlar için istatistiksel özet bilgileri almak için `include='all'` parametresi kullanılabilir.\n",
    "\n",
    "`describe()` fonksiyonunun ayrıca percentiles parametresi de vardır. Bu parametre, özet istatistiklerindeki çeyreklikleri belirlemek için kullanılan yüzde değerleri tanımlamak için kullanılabilir. Varsayılan olarak, `percentiles` parametresi [0.05, 0.95] olarak ayarlanmıştır.\n",
    "\n",
    "Ayrıca, bu fonksiyonu varsayılan olarak tüm sütunlardaki eksik değerleri atlar. Bu davranış, `include='all'` parametresiyle aşılabileceği gibi, ayrıca dropna=False parametresi kullanılarak da değiştirilebilir. Bu, eksik değerlerin de dahil edilmesini sağlar ve eksik değerlerin sayısını özet istatistiklerinde gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.describe(percentiles=[0.05, 0.95]) # diğer dilimleri de görüntülemek için"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d62c1",
   "metadata": {},
   "source": [
    "Veri çerçevesinde veri manipülasyonu, analizi ve temizliği için kullanılan pandas kütüphanesi, veri çerçevesi objeleriyle ilgili birçok metot içermektedir. Bu metotlar, veri işleme sürecinde oldukça yararlıdır. Aşağıda, bazı önemli veri çerçevesi metotları ve kısa açıklamaları yer almaktadır:\n",
    "\n",
    "- `head()`: Veri çerçevesinin ilk birkaç satırını görüntüler.\n",
    "- `tail()`: Veri çerçevesinin son birkaç satırını görüntüler.\n",
    "- `drop()`: Veri çerçevesinden belirtilen sütun veya satırları çıkarır.\n",
    "- `groupby()`: Belirli bir sütuna göre verileri gruplar.\n",
    "- `merge()`: İki veya daha fazla veri çerçevesini belirtilen sütuna göre birleştirir.\n",
    "- `sort_values()`: Belirli bir sütuna göre verileri sıralar.\n",
    "- `pivot_table()`: Veri çerçevesindeki verileri bir tablo halinde yeniden düzenler.\n",
    "- `isna() / isnull()`: Veri çerçevesindeki boş değerleri (NaN) tespit eder.\n",
    "- `fillna()`: Veri çerçevesindeki boş değerleri belirli bir değerle doldurur.\n",
    "- `drop_duplicates()`: Veri çerçevesindeki tekrarlayan satırları çıkarır.\n",
    "- `apply()`: Veri çerçevesinde belirtilen işlevi sütunlar veya satırlar üzerinde uygular.\n",
    "- `map()`: Belirtilen bir işlevi veri çerçevesinin belirli bir sütununa veya serisine uygular.\n",
    "- `replace()`: Belirli bir değeri başka bir değerle değiştirir.\n",
    "- `count()`: Her sütundaki non-null (boş olmayan) veri sayısını verir.\n",
    "- `nunique()`: Her sütundaki benzersiz (tekrar etmeyen) veri sayısını verir.\n",
    "- `sum()`: Her sütundaki sayısal verilerin toplamını verir. Eğer sütunda sayısal veri yoksa o sütun atlanır.\n",
    "- `corr()`: Sütunlar arasındaki korelasyon matrisini oluşturur. Korelasyon, iki değişken arasındaki ilişkinin gücünü ve yönünü ölçer. Değerler -1 ile 1 arasındadır. -1 mükemmel negatif korelasyonu, 1 mükemmel pozitif korelasyonu ve 0 korelasyon olmadığını gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5405f3",
   "metadata": {},
   "source": [
    "`count()`, `sum()`, `mean()`, `min()`, `max()`, `std()` ve `corr()` fonksiyonları hem Series hem de DataFrame veri yapıları için kullanılabilirken `nunique()`, `value_counts()` gibi fonksiyonlar ise yalnızca Series veri yapısı için kullanılabilirdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.Team.value_counts() # hangi takımda kaç kişi var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takımlara ait istatistikler\n",
    "calisan_verileri.groupby('Team').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f430ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.groupby('Team').Team.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.Team.unique() # Tekil verileri getirir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ed2ed",
   "metadata": {},
   "source": [
    "### Eksik veri işlemleri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08196629",
   "metadata": {},
   "source": [
    "#### `None` ve `NaN` veri tipleri\n",
    "\n",
    "Python'da eksik verileri temsil etmek için genellikle iki ana veri tipi kullanılır: `None` ve `NaN`.\n",
    "\n",
    "`None`, bir değişkenin değerinin bilinmediği veya tanımlanmadığı durumlarda kullanılır. Örneğin, bir fonksiyonun dönüş değerinin tanımsız olduğu durumlarda None kullanılır.\n",
    "\n",
    "`NaN (Not a Number)` ise matematiksel işlemler sırasında ortaya çıkan veya eksik sayısal verileri temsil etmek için kullanılır. `NaN`, float veri tipi içinde kullanılır ve matematiksel işlemler sırasında oluşan sayısal hataları temsil eder.\n",
    "\n",
    "Pandas kütüphanesi de eksik verileri temsil etmek için `NaN` değerini kullanır. `NaN` değeri, bir DataFrame veya Series içindeki belirli bir hücrenin değerinin eksik olduğunu belirtir. Pandas, `NaN` değerlerini otomatik olarak tespit eder ve bu değerleri işlem yaparken dikkate alır.\n",
    "\n",
    "Eksik verilerin doğru şekilde yönetilmesi, veri analizi ve modelleme sırasında önemlidir. Pandas, eksik verileri ele almak için çeşitli yöntemler sunar, bunlar arasında eksik verileri silmek, eksik verileri belirli bir değer ile doldurmak veya eksik verileri interpolate etmek yer alır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(None)) # NoneType\n",
    "print(type(np.nan)) # <class 'float'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8864ce",
   "metadata": {},
   "source": [
    "Yukarıdaki kodda görüldüğü gibi `None` ve `NaN` arasındaki fark, temsil ettikleri veri tiplerinden kaynaklanır.\n",
    "\n",
    "`None` bir Python nesnesidir ve bir değişkenin değerinin bilinmediği veya tanımlanmadığı durumlarda kullanılır. `None`, herhangi bir veri tipine ait olmayan özel bir değerdir ve yalnızca Python programlama dilinde kullanılır.\n",
    "\n",
    "`NaN (Not a Number)` ise float veri tipinde kullanılan bir değerdir. Matematiksel işlemler sırasında oluşan veya eksik sayısal verileri temsil etmek için kullanılır. `NaN`, sayısal bir değerin tanımsız veya hesaplanamaz olduğunu belirtir.\n",
    "\n",
    "Yani, `None` bir nesne veya değişkenin tanımlanmadığı veya bilinmediği durumlarda kullanılırken, `NaN` sayısal değerlerde oluşan eksik veya tanımsız durumlar için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d06004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nan + 1) # nan\n",
    "print(None + 1) # unsupported operand type(s) for +: 'NoneType' and 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64cf65",
   "metadata": {},
   "source": [
    "<img src=\"https://i.vgy.me/d78PlT.png\">\n",
    "Öncelikle, bir eksik veri serisi oluşturmak için `None` ve `NaN` değerlerini kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eksik_veri_serisi = np.array([None, np.nan, 1,2,3,\"Merhaba\"])\n",
    "eksik_veri_df = pd.DataFrame(eksik_veri_serisi)\n",
    "print(eksik_veri_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca2999",
   "metadata": {},
   "source": [
    "#### `isnull()`, `isna()`, `notnull()`, `notna()` fonksiyonları\n",
    "Bu seri, 2 tane eksik veri içermektedir. Bu eksik verileri tespit etmek için `isnull()` fonksiyonu kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eksik_veri_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a62ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eksik_veri_df.isnull().sum().sum()) # toplam eksik veri sayısı 2 \n",
    "print(eksik_veri_df.notna().sum().sum()) # eksik olmayan veri sayısı 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0163950",
   "metadata": {},
   "source": [
    "#### `fillna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95479c24",
   "metadata": {},
   "source": [
    "Eksik verileri doldurmak için, `fillna()` fonksiyonunu kullanabiliriz. Bu fonksiyon, belirli bir değerle eksik verileri doldurur. Örneğin, aşağıdaki örnekte eksik verileri 0 ve -999 ile dolduruyoruz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eksik_veri_df.fillna(value=0))\n",
    "print(eksik_veri_df.fillna(value=-999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e978ef",
   "metadata": {},
   "source": [
    "Başka bir seçenek olarak, `ffill` ve `bfill` yöntemlerini kullanarak eksik verileri önceki veya sonraki değerlerle doldurabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "seri_ffill = eksik_veri_df.fillna(method='ffill')  # önceki değerle doldur\n",
    "print(seri_ffill)\n",
    "\n",
    "seri_bfill = eksik_veri_df.fillna(method='bfill')  # sonraki değerle doldur\n",
    "print(seri_bfill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc11080",
   "metadata": {},
   "source": [
    "`ffill` yöntemi, eksik verileri önceki değerle doldururken, `bfill` yöntemi sonraki değerle doldurur.\n",
    "\n",
    "Ayrıca, `interpolate` yöntemini kullanarak, eksik verileri verilerin aritmetik ortalaması veya doğrusal bir model kullanarak interpolate edebiliriz. Bu yöntemi kullanmadan önce serinin nümerik değerlerden oluştuğundan emin olmak gereklidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b05a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "seri_interpolate = pd.Series([1, 2, np.nan, 4, np.nan, 6]).interpolate()\n",
    "print(seri_interpolate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a1d06",
   "metadata": {},
   "source": [
    "Yukarıdaki örnekte, eksik verileri doğrusal bir model kullanarak interpolate ettik. Eksik veriler, verilerin aritmetik ortalaması veya başka bir yöntemle de doldurulabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191c6594",
   "metadata": {},
   "source": [
    "\n",
    "dropna() fonksiyonu, eksik verileri içeren satırları veya sütunları veri kümesinden kaldırmak için kullanılır. Bu fonksiyon, NaN değerlerini içeren satırları veya sütunları veri kümesinden çıkararak yeni bir veri kümesi oluşturur.\n",
    "\n",
    "İlk olarak, bir örnek veri kümesi oluşturalım:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d37163",
   "metadata": {},
   "source": [
    "#### `dropna()`\n",
    "`dropna()` fonksiyonu, eksik verileri içeren satırları veya sütunları veri kümesinden kaldırmak için kullanılır. Bu fonksiyon, NaN değerlerini içeren satırları veya sütunları veri kümesinden çıkararak yeni bir veri kümesi oluşturur.\n",
    "\n",
    "İlk olarak, bir örnek veri kümesi oluşturalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4],\n",
    "                   'B': [5, np.nan, np.nan, 8],\n",
    "                   'C': [9, 10, 11, 12]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd495330",
   "metadata": {},
   "source": [
    "Bu veri kümesinde, NaN değerleri içeren satırlar ve sütunlar var. Bu veri kümesinden `dropna()` fonksiyonunu kullanarak, NaN değerlerini içeren satırları kaldırabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_nulls = df.dropna()\n",
    "print(df_without_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0efd3",
   "metadata": {},
   "source": [
    "`dropna()` fonksiyonu, varsayılan olarak herhangi bir NaN değeri içeren satırı kaldırır ve yeni bir veri kümesi oluşturur. `dropna()` fonksiyonuna axis parametresi ekleyerek, NaN değerleri içeren sütunları kaldırabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_nulls_col = df.dropna(axis=1)\n",
    "print(df_without_nulls_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fbb6f",
   "metadata": {},
   "source": [
    "Bu örnekte, `axis=1` parametresi ile sütunları kaldırdık ve sadece C sütunu kaldı.\n",
    "\n",
    "`dropna()` fonksiyonu, how parametresi ile daha spesifik davranışlar gösterir. Varsayılan olarak `how='any'` olarak ayarlanmıştır, yani herhangi bir eksik değer içeren satırlar veya sütunlar silinir. Ancak, `how='all'` olarak ayarlandığında, tüm değerleri eksik olan satırlar veya sütunlar silinir. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_null = pd.DataFrame({'A': [np.nan, np.nan, np.nan],\n",
    "                            'B': [np.nan, np.nan, np.nan],\n",
    "                            'C': [np.nan, np.nan, np.nan]})\n",
    "print(df_all_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfed2f",
   "metadata": {},
   "source": [
    "Bu örnekte, tüm satırlar veya sütunlar NaN olduğu için, `dropna()` fonksiyonu tüm verileri kaldırdı ve boş bir DataFrame döndürdü.\n",
    "\n",
    "Ayrıca, `dropna()` fonksiyonu `thresh` parametresi ile belirtilen eşik değerinden daha az sayıda geçerli (yani, eksik olmayan) değere sahip olan satırlar veya sütunlar silinir. Örneğin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ff97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh = pd.DataFrame({'A': [1, 2, np.nan, 4],\n",
    "                          'B': [5, np.nan, np.nan, 8],\n",
    "                          'C': [9, 10, np.nan, np.nan]})\n",
    "print(df_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dc1a2",
   "metadata": {},
   "source": [
    "Bu veri kümesinde, en az 2 geçerli değere sahip satırlar veya sütunlar korunacak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresh_dropped = df_thresh.dropna(thresh=2)\n",
    "print(df_thresh_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa86487",
   "metadata": {},
   "source": [
    "Bu örnekte, sadece 2 veya daha fazla geçerli değere sahip olan satırlar ve sütunlar korundu. thresh parametresi, verilerin çeşitli yönlerde temizlenmesine yardımcı olabilir, özellikle büyük veri kümelerinde, verilerin sadece bir kısmı eksikse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6df9c8",
   "metadata": {},
   "source": [
    "### Aykırı veri analizi\n",
    "\n",
    "Pandas, aykırı verilerin tespiti ve analizi için kullanılabilen bir dizi fonksiyona sahiptir. Aykırı veriler, genellikle diğer verilerden önemli ölçüde farklı olan ve istatistiksel analizlerde yanıltıcı sonuçlara neden olabilen verilerdir.\n",
    "\n",
    "Pandas'da aykırı verileri tespit etmek için kullanabileceğiniz birkaç yöntem vardır. Bunlar arasında:\n",
    "\n",
    "1. `describe()` yöntemi: Bu yöntem, veri setinin istatistiklerini hesaplar ve aykırı değerlerin olup olmadığını gösterir. `describe()` yöntemi, veri setindeki en küçük ve en büyük değerleri, ortalamayı, standart sapmayı ve çeyrekliklerin değerlerini gösterir.\n",
    "\n",
    "2. `boxplot()` yöntemi: Bu yöntem, kutu grafiği olarak da bilinir ve veri setindeki aykırı değerleri görselleştirir. Kutu grafiği, veri setinin dağılımını gösterir ve aykırı değerlerin kutunun dışında kalan noktalar olarak belirtilir.\n",
    "\n",
    "3. `quantile()` yöntemi: Bu yöntem, belirli bir yüzdelik aralığında yer alan değerleri hesaplar. Bu yöntem kullanılarak, belirli bir yüzdelik aralığına girmeyen değerler aykırı olarak kabul edilebilir.\n",
    "\n",
    "4. `isolation forest` yöntemi: Bu yöntem, veri setindeki aykırı değerleri tespit etmek için bir makine öğrenmesi algoritmasıdır. Bu yöntem, veri setindeki aykırı değerleri gruplamak için ağaç yapısı kullanır.\n",
    "\n",
    "Bunlar, pandas kütüphanesi ile aykırı veri analizi için kullanılabilecek yöntemlerden sadece birkaçıdır. Bu yöntemler, veri setindeki aykırı değerleri tespit etmek ve işlemek için kullanılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672a683",
   "metadata": {},
   "source": [
    "#### IQR yöntemi\n",
    "\n",
    "IQR (Interquartile Range) yöntemi, aykırı değerleri tanımlamak için kullanılan bir istatistiksel yöntemdir. Bu yöntem, veri dağılımındaki çeyrekliklerin aralığını kullanarak bir alt ve üst sınır belirler ve bu sınırların dışındaki değerleri aykırı olarak tanımlar.\n",
    "\n",
    "IQR, bir veri kümesindeki değerlerin ortalamasının yerine veri dağılımının merkezi eğilim ölçüsü olarak kullanılır. Veri kümesindeki değerlerin çoğu IQR içinde kaldığı için, IQR yöntemi aykırı değerleri belirlemek için daha güvenilirdir. IQR, verilerin ortalamasına karşı daha dayanıklıdır çünkü sadece veri kümesinin ortasındaki değerlerin aralığını kullanır.\n",
    "\n",
    "IQR yöntemi kullanarak aykırı değerleri belirlemek için, verilerin 1. ve 3. çeyrekliklerinin aralığı (yani IQR) hesaplanır. Ardından, alt sınır Q1 - 1.5 x IQR ve üst sınır Q3 + 1.5 x IQR şeklinde hesaplanır. Bu sınırların dışındaki herhangi bir değer aykırı olarak kabul edilir.\n",
    "\n",
    "Örneğin, bir veri kümesinde Q1 = 20 ve Q3 = 50 olsun. Bu durumda, IQR = Q3 - Q1 = 50 - 20 = 30 olacaktır. Alt sınır, 20 - 1.5 x 30 = -5, üst sınır ise 50 + 1.5 x 30 = 95 olacaktır. Veri kümesindeki herhangi bir değer -5'ten küçük veya 95'ten büyükse aykırı olarak kabul edilecektir.\n",
    "\n",
    "Aşağıdaki örnekte `titanic` veri seti üzerinde bir aykırı veri analizi gösterilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3761166",
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_seti = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n",
    "veri_seti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_seti.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri setinin doldurulması\n",
    "doldurulmus_veri = veri_seti.fillna(method=\"bfill\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85668d87",
   "metadata": {},
   "source": [
    "Aşağıdaki komut, \"Age\" sütununun istatistiksel özetini oluşturur. İstatistiksel özet, sütunun minimum ve maksimum değerleri, ortalama, standart sapma, medyan ve çeyreklikler gibi önemli özelliklerini içerir. \"describe()\" fonksiyonu, veri çerçevesindeki sayısal sütunlar için bu tür istatistiksel özetler oluşturmak için sıklıkla kullanılan bir yöntemdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc697657",
   "metadata": {},
   "outputs": [],
   "source": [
    "doldurulmus_veri.Age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b605855",
   "metadata": {},
   "source": [
    "Aşağıdaki komut, \"Age\" adlı bir değişkenin kutu grafiğini çizmek için Pandas kütüphanesinin \"plot\" fonksiyonunu kullanır. \n",
    "\n",
    "Bu komut, bir veri çerçevesindeki \"Age\" sütununu seçerek, sütundaki sayısal verilerin çeyrekler arası mesafeleri, minimum ve maksimum değerleri, olası aykırı değerleri vb. görselleştiren bir kutu grafiği çizer. Bu grafiği kullanarak, veri setindeki \"Age\" sütunundaki dağılımı görsel olarak anlayabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672da117",
   "metadata": {},
   "outputs": [],
   "source": [
    "doldurulmus_veri.Age.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = doldurulmus_veri.Age.quantile(q=0.25)\n",
    "Q3 = doldurulmus_veri.Age.quantile(q=0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Q1: {}, Q3: {}, IQR: {}\".format(Q1, Q3, IQR)) # Q1: 21.0, Q3: 39.0, IQR: 18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75697692",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_sinir = Q1-1.5*IQR\n",
    "ust_sinir = Q3 + 1.5*IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_sinir, ust_sinir # (-6.0, 66.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a47274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt sınırın altında veri var mı?\n",
    "doldurulmus_veri.Age[doldurulmus_veri.Age < alt_sinir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c534d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üst sınırın üzerinde veri var mı?\n",
    "doldurulmus_veri.Age[doldurulmus_veri.Age>ust_sinir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ad863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt sınır ve üst sınırı aşan verileri traşladık\n",
    "doldurulmus_veri.Age[doldurulmus_veri.Age > ust_sinir] = ust_sinir\n",
    "doldurulmus_veri.Age[doldurulmus_veri.Age < alt_sinir] = alt_sinir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8504534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeniden kontrol edildiğinde\n",
    "doldurulmus_veri.Age.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8755d5a",
   "metadata": {},
   "source": [
    "#### Z-Skoru yöntemi\n",
    "\n",
    "Z-skoru yöntemi, verilerin ortalama ve standart sapma değerlerini kullanarak aykırı değerleri belirlemek için kullanılan bir yöntemdir. Bu yöntemde, verilerin standart sapma değerlerine göre ne kadar uzağa olduklarına göre bir skor verilir. Skorların dağılımı normal dağılıma göre ayarlanır ve genellikle 3'ün üzerinde veya altında kalan skorlar aykırı değer olarak kabul edilir.\n",
    "\n",
    "Z-skoru hesaplamak için, her bir veri noktasının ortalama değerden uzaklığının standart sapmaya bölünmesi gerekir. Formül aşağıdaki gibidir:\n",
    "\n",
    "Z = (x - mean) / std\n",
    "\n",
    "Burada:\n",
    "- x, herhangi bir veri noktası\n",
    "- mean, veri setinin ortalaması\n",
    "- std, veri setinin standart sapması\n",
    "\n",
    "Örneğin, bir veri setinde ortalama değer 50 ve standart sapma 10 ise, bir veri noktası 70 olsun. Z-skoru aşağıdaki şekilde hesaplanabilir:\n",
    "\n",
    "Z = (70 - 50) / 10 = 2\n",
    "\n",
    "Bu veri noktası, veri setinin normal dağılımına göre 2 standart sapma yukarıdadır. Eğer bu değer 3'ten büyükse veya -3'ten küçükse, bu veri noktası aykırı değer olarak kabul edilir.\n",
    "\n",
    "Pandas kütüphanesi ile Z-skoru yöntemi kullanılarak aykırı değerleri bulmak için, \"zscore\" fonksiyonu kullanılabilir. Bu fonksiyon, belirli bir sütundaki her bir veri noktasının Z-skorunu hesaplar ve bunları yeni bir sütuna ekler. Ardından, belirli bir eşik değerine göre aykırı değerleri seçmek için bu sütunu filtrelemek mümkündür. Örneğin:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verileri yükle\n",
    "df = doldurulmus_veri\n",
    "\n",
    "# 'degerler' sütunundaki her bir veri noktasının Z-skorunu hesapla\n",
    "df['z_score'] = (df['Age'] - df['Age'].mean()) / df['Age'].std()\n",
    "\n",
    "# Z-skoru eşiği 3 olan aykırı değerleri seç\n",
    "outliers = df.loc[df['z_score'].abs() > 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a19120",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3ff85",
   "metadata": {},
   "source": [
    "### Veri dönüşüm işlemleri\n",
    "Pandas kütüphanesi, verileri manipüle etmek için birçok işlevsellik sunar. Bu işlevsellikler arasında veri dönüşümleri, normalizasyon, standardizasyon ve kesikli hale getirme gibi işlemler de bulunur. \n",
    "\n",
    "- Veri dönüşümleri: Veri dönüşümleri, verilerin farklı birimler veya formatlarla sunulduğu durumlarda kullanışlıdır. Pandas'ta veri dönüşümleri, \"apply\" ve \"map\" fonksiyonları gibi farklı yöntemlerle gerçekleştirilebilir.\n",
    "\n",
    "- Normalizasyon: Normalizasyon, verilerin arasındaki değerleri sınırlandırarak verilerin dağılımını düzenler. Bu işlem sayesinde farklı birimlerdeki veriler aynı ölçekte karşılaştırılabilir hale gelir. Normalizasyon için genellikle Min-Max Normalizasyonu kullanılır.\n",
    "\n",
    "- Standardizasyon: Standardizasyon, verilerin arasındaki standart sapmaları kullanarak verilerin dağılımını düzenler. Bu işlem sayesinde farklı birimlerdeki verilerin dağılımları daha anlamlı hale gelir. Standardizasyon için genellikle Z-skoru yöntemi kullanılır.\n",
    "\n",
    "- Kesikli hale getirme: Kesikli hale getirme, sürekli sayısal verileri belirli aralıklarla kesikli hale getirerek verilerin anlamlı hale gelmesini sağlar. Bu işlem, özellikle makine öğrenimi modellerinde kategorik değişkenlerle birlikte kullanılmak üzere faydalıdır.\n",
    "\n",
    "Örnek olarak, veri setindeki bir sütunu normalizasyon, standardizasyon veya kesikli hale getirme işlemlerinden biri ile işleyebilirsiniz. Örneğin, \"Age\" sütununu 0 ile 1 arasındaki değerlere normalizasyon yaparak işleyebilirsiniz:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf76a7",
   "metadata": {},
   "source": [
    "#### Normalizasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['Age_Normalized'] = scaler.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73358d",
   "metadata": {},
   "source": [
    "Bu kodda, \"Age\" sütununun değerleri Min-Max Normalizasyon yöntemi ile 0 ile 1 arasındaki değerlere dönüştürülüp \"Age_Normalized\" adlı yeni bir sütunda saklanır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb696e",
   "metadata": {},
   "source": [
    "Ya da benzer işlem kendi yazacağımız denklem üzerinden de gerçekleştirilebilir. Aşağıdaki kodlar bu amacı yerine getirmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e403da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yas = doldurulmus_veri.Age\n",
    "normalize_edilmis = (yas - yas.min())/(yas.max()-yas.min())\n",
    "normalize_edilmis.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e05f6",
   "metadata": {},
   "source": [
    "#### Standardizasyon\n",
    "\n",
    "Tablodaki 'Salary' sütununu standardize etmek için örnek bir pandas kodu aşağıdaki gibi olabilir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Örnek bir veri seti\n",
    "data = {'Name': ['Ali', 'Veli', 'Ahmet', 'Mehmet'],\n",
    "        'Age': [27, 31, 25, 29],\n",
    "        'Salary': [5000, 7000, 4500, 6000]}\n",
    "\n",
    "# Verileri bir pandas DataFrame nesnesine dönüştürme\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Verileri standardize etme\n",
    "scaler = StandardScaler()\n",
    "df['Standardized_Salary'] = scaler.fit_transform(df[['Salary']])\n",
    "\n",
    "# Sonuçları yazdırma\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc44fad",
   "metadata": {},
   "source": [
    "Bu kodda, `StandardScaler` fonksiyonu ile `Salary` sütunu standart normal dağılım (ortalama 0 ve standart sapma 1) haline getiriliyor. Bu işlem, tüm veri setinin aynı ölçekte olmasını sağlamak için yapılır ve makine öğrenmesi modelleri gibi bazı analizlerde gereklidir. Yeni standartlaştırılmış sütun, `Standardized_Salary` olarak adlandırılır ve DataFrame'e eklenir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2c36c",
   "metadata": {},
   "source": [
    "#### Kesikli hale getirme\n",
    "\n",
    "Kesikli hale getirme (discretization), bir sürekli değişkenin belirli aralıklara ayrılması işlemidir. Bu işlem sayesinde veriler daha kolay yorumlanabilir ve anlaşılabilir hale gelir.\n",
    "\n",
    "Pandas kütüphanesi ile kesikli hale getirme işlemi `cut()` fonksiyonu ile yapılabilir. Bu fonksiyon, bir aralık serisini kesikli kategorik bir değişkene dönüştürür. Örneğin, bir veri setindeki yaş değişkenini belirli aralıklara bölerek yaş kategorileri elde etmek için kullanılabilir.\n",
    "\n",
    "Aşağıda örnek bir kesikli hale getirme işlemi bulunmaktadır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek veri seti\n",
    "veri = pd.DataFrame({'yaş': [25, 36, 42, 29, 51, 46, 39, 33, 28, 24]})\n",
    "\n",
    "# Yaş aralıklarını belirleme\n",
    "araliklar = [0, 30, 40, 60]\n",
    "\n",
    "# Yaş değişkenini kesikli hale getirme\n",
    "veri['yaş_kategorisi'] = pd.cut(veri['yaş'], araliklar)\n",
    "\n",
    "print(veri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b2984",
   "metadata": {},
   "source": [
    "Bu kod örneği, `yaş` değişkenindeki her bir değeri belirtilen aralıklara göre kesikli hale getirir ve yeni bir `yaş_kategorisi` değişkeni oluşturur. Çıktı aşağıdaki gibi olacaktır:\n",
    "\n",
    "```\n",
    "   yaş yaş_kategorisi\n",
    "0   25        (0, 30]\n",
    "1   36       (30, 40]\n",
    "2   42       (40, 60]\n",
    "3   29        (0, 30]\n",
    "4   51       (40, 60]\n",
    "5   46       (40, 60]\n",
    "6   39       (30, 40]\n",
    "7   33       (30, 40]\n",
    "8   28        (0, 30]\n",
    "9   24        (0, 30]\n",
    "```\n",
    "\n",
    "Görüldüğü gibi, her bir yaş değeri, belirlenen aralıklara göre bir kategoriye atanmıştır. Bu şekilde, `yaş` değişkeni daha anlamlı ve yorumlanabilir bir hale getirilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535db8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "yas_kategorileri = [\"cocuk\", \"genc\", \"yasli\"]\n",
    "pd.cut(x=veri['yaş'], bins=araliklar, labels=yas_kategorileri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877834c",
   "metadata": {},
   "source": [
    "#### One-hot encoding\n",
    "\n",
    "One-Hot Encoding, kategorik değişkenlerin (categorical variables) makine öğrenmesi algoritmalarında kullanılabilmesi için sayısal veriye dönüştürülmesi işlemidir. Bu işlem, her kategorik değişkenin ayrı bir özellik olarak ele alındığı ve bu özelliklerin sadece 0 veya 1 değerleri alabildiği yeni bir veri kümesi oluşturur. Bu yöntem, sınıflandırma algoritmalarının daha doğru sonuçlar vermesine yardımcı olur.\n",
    "\n",
    "Örnek olarak, bir \"renk\" değişkeni düşünelim. Bu değişken \"kırmızı\", \"yeşil\" ve \"mavi\" gibi 3 farklı kategorik değer alabilsin. One-Hot Encoding ile bu değişken, \"renk_kırmızı\", \"renk_yeşil\" ve \"renk_mavi\" olmak üzere 3 farklı özellik haline dönüştürülür. Her bir özellik, orijinal \"renk\" değişkeninin o değerine sahipse 1, diğer durumlarda 0 değerini alır.\n",
    "\n",
    "Pandas kütüphanesi, One-Hot Encoding işlemi için get_dummies() fonksiyonunu sağlar. Bu fonksiyon, kategorik değişkenleri otomatik olarak bulur ve yeni özellikler haline dönüştürür. Örnek kullanım aşağıdaki gibidir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40725cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek veri seti\n",
    "data = {'renk': ['kırmızı', 'mavi', 'yeşil', 'mavi', 'kırmızı']}\n",
    "\n",
    "# Veri setini DataFrame'e dönüştürme\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-Hot Encoding işlemi\n",
    "one_hot_encoded = pd.get_dummies(df['renk'])\n",
    "\n",
    "# Yeni özellikleri DataFrame'e ekleme\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "# Sonuçları görüntüleme\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637ebba",
   "metadata": {},
   "source": [
    "Benzer işlem `titanic` veri setine de yapılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_seti.Embarked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931aa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "veri_seti.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kukla değişken - one-hot encoding\n",
    "pd.get_dummies(veri_seti.Embarked).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc4bd9",
   "metadata": {},
   "source": [
    "### Formül Uygulama\n",
    "\n",
    "Pandas kütüphanesi, `map()` ve `apply()` gibi fonksiyonlar aracılığıyla veri işleme işlevselliği sağlar.\n",
    "\n",
    "`map()` fonksiyonu, bir pandas Serisi'ndeki tüm öğeleri değiştirmek için kullanılır. Bu işlev, bir sözlük, işlev veya Seri nesnesi alabilir ve Seri öğelerini değiştirmek için bu nesneleri kullanır. Örneğin aşağıdaki kod, Salary Serisi'deki tüm öğelere 200.000 artırarak ve sonucu ekrana yazdıracaktır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.Salary.map(lambda x: x+200000) # Salary lere toplu artış"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21282579",
   "metadata": {},
   "source": [
    "`apply()` fonksiyonu ise, bir DataFrame'in bir sütununda veya satırında işlevleri uygulamak için kullanılır. `apply()` fonksiyonu, `map()` fonksiyonuna benzer şekilde işlevlerin uygulanmasında kullanılır ancak, DataFrame veri yapısında uygulanır. Aşağıdaki kod, istenilen DataFrame sütununda bir yazılan fonksiyonun işlemini yapacak ve sonucu ekrana yazdıracaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fonksiyon_ismi(x):\n",
    "    return x + 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.Salary.apply(fonksiyon_ismi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36109ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sayi_formatla(x):\n",
    "    return f\"{x:.1f}\"\n",
    "\n",
    "calisan_verileri[\"Bonus %\"].apply(sayi_formatla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec628a80",
   "metadata": {},
   "source": [
    "Aşağıdaki örneklerde ise pandas veri çerçevelerine yeni bir sütun eklemek için işlemler gösterilmiştir. Yeni bir sütun oluşturmak için iki aşama gereklidir:\n",
    "\n",
    "- Yeni bir sütun oluşturmak ve ona bir ad vermek\n",
    "-  Yeni sütunun her bir hücresine değer atamak\n",
    "\n",
    "Bunun için [] operatörü ve atama işlemi = kullanılır. Örneğin, aşağıdaki kod bir veri çerçevesine yeni bir sütun ekleyecek ve içerisine sabit bir \"herhangi bir değer\" yazdıracaktır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri['yeni_sutun'] = 'herhangi bir değer'\n",
    "calisan_verileri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri['Yeni Sütun'] = np.random.randint(\n",
    "    low=10, high=20,\n",
    "    size=calisan_verileri.shape[0])  # yeni sütun rassal verilerden oluşturuldu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e873aa",
   "metadata": {},
   "source": [
    "Örneğin, aşağıdaki kod \"Yeni Sütun\" sütunundaki her bir değeri 2 ile çarpacaktır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri['Yeni Sütun'] = calisan_verileri['Yeni Sütun'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629ef36",
   "metadata": {},
   "source": [
    "Burada, calisan_verileri['Yeni Sütun'] * 2 ifadesi, Yeni Sütun sütunundaki her bir değeri 2 ile çarpar ve sonucunu tekrar calisan_verileri['Yeni Sütun'] sütununa atar. \n",
    "\n",
    "Nüfusu yüksek olan şehirleri bir sütunda tutmak istersek şu şekilde bir kod yazabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sehirler['nufusu_yuksek'] = sehirler.nufuslar > 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482817dd",
   "metadata": {},
   "source": [
    "`sort_values()` fonksiyonu, bir veri çerçevesindeki sütunlara göre sıralama yapmaya yarayan bir fonksiyondur. Bu fonksiyon, veri çerçevesindeki belirli bir sütuna göre verileri küçükten büyüğe veya büyükten küçüğe doğru sıralama yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0edf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.sort_values(by=['Salary', 'Bonus %'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a1c92",
   "metadata": {},
   "source": [
    "`rename()` fonksiyonu, bir veya daha fazla ekseni, satır veya sütun etiketlerini yeniden adlandırmak için kullanılır.\n",
    "\n",
    "Fonksiyonun genel kullanımı aşağıdaki gibidir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "calisan_verileri.rename(columns={\n",
    "    'Bonus %': 'Bonus__%',\n",
    "    'Team': 'Teams'\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-maintenance",
   "metadata": {},
   "source": [
    "## Veri Seçme ve Verilere Ulaşma\n",
    "\n",
    "Dosya yüklendikten ve veri setini anladıktan sonra, bazı verilere erişmek isteyebiliriz. Pandas, veri seçme, indeksleme ve filtreleme işlemleri için birçok farklı yöntem sunar. Bu yöntemlerin en sık kullanılanları şunlardır:\n",
    "\n",
    "- `İndeksleme operatörü ([])` : Bu operatör ile belirli bir sütun ya da satır seçilebilir. Örneğin, veri çerçevesindeki 'Name' sütununu seçmek için df['Name'] kullanılır.\n",
    "- `.loc[]` : Bu metot ile satır ve sütun isimleri veya konumlarına göre seçim yapılabilir. Örneğin, veri çerçevesindeki 3. satırı ve 'Age' sütununu seçmek için df.loc[3, 'Age'] kullanılır.\n",
    "- `.iloc[]` : Bu metot ile satır ve sütun konumlarına göre seçim yapılabilir. Örneğin, veri çerçevesindeki 2. satırı ve 3. sütunu seçmek için df.iloc[1, 2] kullanılır.\n",
    "- `Boolean indeksleme` : Bu metot ile belirli koşulları sağlayan satırlar seçilebilir. Örneğin, veri çerçevesindeki yaş değeri 30'dan büyük olan satırların seçimi için df[df['Age'] > 30] kullanılır.\n",
    "- `.query()` : Bu metot ile belirli koşullara göre satırlar seçilebilir. Örneğin, veri çerçevesindeki yaş değeri 30'dan büyük olan satırların seçimi için df.query('Age > 30') kullanılır.\n",
    "- `.isin()` : Bu metot ile belirli bir değere sahip olan satırlar seçilebilir. Örneğin, veri çerçevesindeki 'Gender' sütununda 'Female' değerine sahip olan satırların seçimi için df[df['Gender'].isin(['Female'])] kullanılır.\n",
    "- `.between()` : Bu metot ile belirli bir aralıkta olan değerlere sahip olan satırlar seçilebilir. Örneğin, veri çerçevesindeki yaş değeri 20 ile 30 arasında olan satırların seçimi için df[df['Age'].between(20, 30)] kullanılır.\n",
    "\n",
    "Bu yöntemlerin her biri, farklı durumlar için kullanışlıdır ve veri çerçevelerinde veri seçimi, indeksleme ve filtreleme işlemlerinin kolay ve esnek bir şekilde yapılmasına olanak tanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d65fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calisan_verileri[\"Team\"])  # sadece Team sütununu getirir.\n",
    "calisan_verileri[[\"Team\", \"Bonus %\"]]  # iki sütunu birlikte getirir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd4b7e",
   "metadata": {},
   "source": [
    "Ayrıca, belli bir koşulu sağlayan satırlara erişmek için de `loc[]` fonksiyonunu kullanabiliriz. Bu fonksiyon, koşulu sağlayan satırları getirir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661b9b0",
   "metadata": {},
   "source": [
    "### iloc\n",
    "\n",
    "`iloc` fonksiyonu, verilerin indeks numaralarına göre erişim sağlar. İndeks numarası, satırın konumunu belirtir ve sütun adı belirtilmezse tüm sütunlar döndürülür. Örneğin, aşağıdaki DataFrame nesnesinde, \"isim\", \"yaş\" ve \"şehir\" sütunlarındaki 1. indeksteki satırlara erişmek istediğimizi varsayalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf81ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'isim': ['Ahmet', 'Mehmet', 'Ali', 'Ayşe'],\n",
    "    'yaş': [28, 22, 30, 25],\n",
    "    'şehir': ['İstanbul', 'Ankara', 'İzmir', 'Bursa']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# İlk satırlara erişim\n",
    "print(df.iloc[1])  # Sadece bir satır döndürür\n",
    "print(df.iloc[[1]])  # Bir DataFrame nesnesi döndürür\n",
    "print(df.iloc[[1, 2]])  # İki satırı içeren bir DataFrame nesnesi döndürür\n",
    "\n",
    "# İlk satırlara ve belirli sütunlara erişim\n",
    "print(df.iloc[1, 0])  # Sadece bir değer döndürür\n",
    "print(df.iloc[\n",
    "    [1, 2],\n",
    "    0:2])  # İki satırı ve ilk iki sütunu içeren bir DataFrame nesnesi döndürür"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c8512",
   "metadata": {},
   "source": [
    "### loc\n",
    "\n",
    "`loc` fonksiyonu, satırların etiket veya koşullara göre erişim sağlar. Etiket veya koşul belirtilmezse, tüm satırlar döndürülür. Örneğin, aşağıdaki DataFrame nesnesinde, \"isim\", \"yaş\" ve \"şehir\" sütunlarındaki \"Mehmet\" ve \"Ali\" isimli satırlara erişmek istediğimizi varsayalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a94dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'isim': ['Ahmet', 'Mehmet', 'Ali', 'Ayşe'],\n",
    "    'yaş': [28, 22, 30, 25],\n",
    "    'şehir': ['İstanbul', 'Ankara', 'İzmir', 'Bursa']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Etiket veya koşullara göre erişim\n",
    "print(df.loc[df['isim'] == 'Mehmet'])  # Bir DataFrame nesnesi döndürür\n",
    "print(df.loc[df['isim'].isin(\n",
    "    ['Mehmet', 'Ali'])])  # İki satırı içeren bir DataFrame nesnesi döndürür\n",
    "\n",
    "# Etiket veya koşullara göre erişim ve belirli sütunlar\n",
    "print(df.loc[df['isim'] == 'Mehmet', 'yaş'])  # Sadece bir değer döndürür\n",
    "print(df.loc[df['isim'].isin(['Mehmet', 'Ali']), ['yaş', 'şehir']])  #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4835295",
   "metadata": {},
   "source": [
    "- df[sütun]: DataFrame'den tek bir sütun veya sütun dizisi seçin; özel durum kolaylıkları: Boolean array (satırları filtreleme), slice (satırları dilimleme) veya Boolean DataFrame (bir kriterle değerleri ayarlama)\n",
    "- df.loc[satırlar]: Etiketleme ile DataFrame'den tek bir satır veya alt küme seçin\n",
    "- df.loc[:, sütunlar]: Etiketleme ile tek bir sütun veya sütun alt kümesini seçin\n",
    "- df.loc[satırlar, sütunlar]: Hem satır(lar) hem de sütun(lar) etiketle seçin\n",
    "- df.iloc[satırlar]: DataFrame'den tek bir satır veya satır alt kümesini konumla seçin\n",
    "- df.iloc[:, sütunlar]: Tamsayı pozisyonu ile tek bir sütun veya sütun alt kümesini seçin\n",
    "- df.iloc[satırlar, sütunlar]: Hem satır(lar) hem de sütun(lar) tamsayı pozisyonu ile seçin\n",
    "- df.at[satır, sütun]: Bir satır ve sütun etiketiyle tek bir skaler değeri seçin\n",
    "- df.iat[satır, sütun]: Bir satır ve sütun pozisyonu (tamsayılar) ile tek bir skaler değeri seçin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb83a4",
   "metadata": {},
   "source": [
    "## Sonuç\n",
    "Bu bölümde, pandas'ın önemli bir araç olmasını sağlayan temel özelliklerini inceledik. Uygulamalı örneklerle kütüphanenin yeteneklerini keşfettik. Seriler ve Veri Çerçeveleri gibi veri nesneleri, int64, float ve object gibi veri tipleri ve veri dönüştürme işlemleri için farklı yöntemler hakkında bilgi sahibi olduk. Daha sonra, veri seçimi ve indeksleme gibi farklı yöntemlerle veri manipülasyonu gerçekleştirdik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e602be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}